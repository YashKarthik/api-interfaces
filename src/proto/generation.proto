syntax = 'proto3';
package gooseai;
option go_package = "./;generation";
import "tensors.proto";

enum FinishReason {
  NULL = 0;
  LENGTH = 1;
  STOP = 2;
  ERROR = 3;
  FILTER = 4;
}

enum ArtifactType {
  ARTIFACT_NONE = 0;
  ARTIFACT_IMAGE = 1;
  ARTIFACT_VIDEO = 2;
  ARTIFACT_TEXT = 3;
  ARTIFACT_TOKENS = 4;
  ARTIFACT_EMBEDDING = 5;
  ARTIFACT_CLASSIFICATIONS = 6;
  ARTIFACT_MASK = 7;
  ARTIFACT_LATENT = 8;
  ARTIFACT_TENSOR = 9;
}

// Generally, a GPT BPE 16-bit token, paired with an optional string representation.
message Token {
  optional string text = 1;
  uint32 id = 2;
}

// Sequence of tokens, paired with the id of the tokenizer used to generate them.
message Tokens {
  repeated Token tokens = 1;
  optional string tokenizer_id = 2;
}

// A tangible Artifact, such as an image, video, or text that is used for input
// or output.
message Artifact {
  uint64 id = 1;
  ArtifactType type = 2;
  string mime = 3;                // MIME type identifier, e.g. "image/png"
  optional string magic = 4;      // Magic number, e.g. "PNG"
  oneof data {
    bytes binary = 5;             // Binary data, e.g. PNG image
    string text = 6;              // Text data, e.g. text prompt
    Tokens tokens = 7;            // Tokenized text data, e.g. GPT tokens
    ClassifierParameters classifier = 11;
    tensors.Tensor tensor = 14;   // torch.Tensor:
                                  //    RGB tensor (C,H,W)
                                  //    VAE latent (C,H//8,W//8, assuming VAE-f8)
  }
  uint32 index = 8;               // Index of this artifact in input/output list
  FinishReason finish_reason = 9; // Reason for finishing, if applicable
  uint32 seed = 10;               // Seed used to generate this artifact
  string uuid = 12;               // UUIDv4 of the artifact, used for asset lookup
  uint64 size = 13;               // Size of the artifact in bytes
}

enum MaskedAreaInit {
  MASKED_AREA_INIT_ZERO = 0;
  MASKED_AREA_INIT_RANDOM = 1;
  MASKED_AREA_INIT_ORIGINAL = 2;
}

enum WeightMethod {
  TEXT_ENCODER = 0;
  CROSS_ATTENTION = 1;
}

// A set of parameters for each individual Prompt.
message PromptParameters {
  optional bool init = 1;
  optional float weight = 2;
}

// A Prompt is a special type of Artifact that is used to generate an output.
// There can be multiple Prompts that affect the same output. Currently, the
// only Prompts supported are:
//   - Text (singular)
//   - Init Image (singular, optional, type ARTIFACT_IMAGE, with init=true)
//   - Mask (singular, optional, Artifact type ARTIFACT_MASK)
message Prompt {
  optional PromptParameters parameters = 1;
  oneof prompt {
    string text = 2;
    Tokens tokens = 3;
    Artifact artifact = 4;
  }
}

// DiffusionSampler identifies which sampler to use for Diffusion, and represents
// the internal set of supported samplers.
enum DiffusionSampler {
  SAMPLER_DDIM = 0;
  SAMPLER_DDPM = 1;
  SAMPLER_K_EULER = 2;
  SAMPLER_K_EULER_ANCESTRAL = 3;
  SAMPLER_K_HEUN = 4;
  SAMPLER_K_DPM_2 = 5;
  SAMPLER_K_DPM_2_ANCESTRAL = 6;
  SAMPLER_K_LMS = 7;
  SAMPLER_K_DPMPP_2S_ANCESTRAL = 8;
  SAMPLER_K_DPMPP_2M = 9;
}

// Parameters that affect the behavior of the sampler, typically used for CFG.
message SamplerParameters {
  optional float eta = 1;
  optional uint64 sampling_steps = 2;
  optional uint64 latent_channels = 3;
  optional uint64 downsampling_factor = 4;
  optional float cfg_scale = 5;
  optional float init_noise_scale = 6; // defaults to 0.99
}

// Unused, but reserved for future use. Adjustments to the latents after
// initialization.
message ConditionerParameters {
  optional string vector_adjust_prior = 1;
  optional Model conditioner = 2;
}

// Future, unimplemented.
enum Upscaler {
  UPSCALER_RGB = 0;
  UPSCALER_GFPGAN = 1;
  UPSCALER_ESRGAN = 2;
}

// When does this schedule definition apply?
message ScheduleParameters {
  optional float start = 1;     // 0.0 to 1.0
  optional float end = 2;       // 0.0 to 1.0
  optional float value = 3;     // float value to apply on this schedule
}

// Parameters that apply to this block of the schedule.
message StepParameter {
  float scaled_step = 1;
  optional SamplerParameters sampler = 2;
  optional ScheduleParameters schedule = 3;
  optional GuidanceParameters guidance = 4;
}

// Presets for CLIP guidance.
enum GuidancePreset {
  GUIDANCE_PRESET_NONE = 0;
  GUIDANCE_PRESET_SIMPLE = 1;
  GUIDANCE_PRESET_FAST_BLUE = 2;
  GUIDANCE_PRESET_FAST_GREEN = 3;
  GUIDANCE_PRESET_SLOW = 4;
  GUIDANCE_PRESET_SLOWER = 5;
  GUIDANCE_PRESET_SLOWEST = 6;
}

enum ModelArchitecture {
  MODEL_ARCHITECTURE_NONE = 0;
  MODEL_ARCHITECTURE_CLIP_VIT = 1;
  MODEL_ARCHITECTURE_CLIP_RESNET = 2;
  MODEL_ARCHITECTURE_LDM = 3;
}

message Model {
  ModelArchitecture architecture = 1;
  string publisher = 2;
  string dataset = 3;
  float version = 4;
  string semantic_version = 5;
  string alias = 6;
}

message CutoutParameters {
  repeated CutoutParameters cutouts = 1;    // Nested cutouts, unsupported
  optional uint32 count = 2;                // 0 to n, usually 8 to 32, 0 inner
  optional float gray = 3;                       // 0.0 to 1.0, defaults to 0.2
  optional float blur = 4;                       // percentage of cutouts to blur
  optional float size_power = 5;            // defaults to inner: 0.5, outer: 0.0
}

// GuidanceScheduleParameters are used to define a schedule for CLIP guidance, and
// are used to define the behavior of the guidance over time. They are relative
// to the total number of steps, and are scaled to the number of steps in the
// current run.
message GuidanceScheduleParameters {
  float duration = 1;
  float value = 2;
}

// Parameters that affect the behavior of the guidance, typically used for CLIP.
// We can specify more than one model, and the guidance will be a weighted sum
// of the models.
message GuidanceInstanceParameters {
  repeated Model models = 2;                // models to use for this set
  optional float guidance_strength = 3;     // 0.0 to 1.0, usually 0.05 to 0.225
  repeated GuidanceScheduleParameters schedule = 4; // when to apply guidance
  optional CutoutParameters cutouts = 5;    // cutout parameters
  optional Prompt prompt = 6;               // prompt to use for guidance
}

// Parameters that affect the behavior of the guidance, typically used for CLIP.
// The omission of this field implies the default guidance of CFG.
message GuidanceParameters {
  GuidancePreset guidance_preset = 1;                // base preset for guidance
  repeated GuidanceInstanceParameters instances = 2; // guidance instances
}

message TransformType {
  oneof type {
      DiffusionSampler diffusion = 1;
      Upscaler upscaler = 2;
      TransformSequence sequence = 3;
  }
}

message ImageParameters {
  optional uint64 height = 1;
  optional uint64 width = 2;
  repeated uint32 seed = 3;
  optional uint64 samples = 4;
  optional uint64 steps = 5;
  optional TransformType transform = 6;
  repeated StepParameter parameters = 7;
  optional MaskedAreaInit masked_area_init = 8; // defaults to MASKED_AREA_INIT_ZERO 
}

enum Action {
  ACTION_PASSTHROUGH = 0;
  ACTION_REGENERATE_DUPLICATE = 1;
  ACTION_REGENERATE = 2;
  ACTION_OBFUSCATE_DUPLICATE = 3;
  ACTION_OBFUSCATE = 4;
  ACTION_DISCARD = 5;
}

//
// Artifact classification parameters.
//

enum ClassifierMode {
  CLSFR_MODE_ZEROSHOT = 0;
  CLSFR_MODE_MULTICLASS = 1;
  /*CLSFR_MODE_ODDSRATIO = 2;*/
}

message ClassifierConcept {
  string concept = 1;
  optional float threshold = 2;
}

message ClassifierCategory {
  string name = 1;
  repeated ClassifierConcept concepts = 2;
  optional float adjustment = 3;
  optional Action action = 4;
  optional ClassifierMode classifier_mode = 5;
}

message ClassifierParameters {
  repeated ClassifierCategory categories = 1;
  repeated ClassifierCategory exceeds = 2;
  optional Action realized_action = 3;
}


//
// Interpolation
//

enum InterpolateMode {
  INTERPOLATE_LINEAR = 0;
  INTERPOLATE_RIFE = 1;
  INTERPOLATE_VAE_LINEAR = 2;
  INTERPOLATE_VAE_SLERP = 3;
}

// Interpolation between two images applied at specified blend ratios
message InterpolateParameters {
  repeated float ratios = 1;
  optional InterpolateMode mode = 2;
}


//
// Transforms
//

enum BorderMode {
  BORDER_REFLECT = 0;   // reflect image values across the border
  BORDER_REPLICATE = 1; // replicate border values outside the image
  BORDER_WRAP = 2;      // wrap around / tile the image values
  BORDER_ZERO = 3;      // use 0 for locations outside the image
}

enum ColorMatchMode {
  COLOR_MATCH_HSV = 0;  // match hue, saturation, and value histograms
  COLOR_MATCH_LAB = 1;  // match lightness, a, and b histograms
  COLOR_MATCH_RGB = 2;  // match red, green, and blue histograms
}

message TransformAddNoise {
  float amount = 1;         // amount of gaussian noise to add
  optional uint32 seed = 2; // random seed for the noise generation
}

message TransformBlend {
  float amount = 1;     // blend amount from 0 to 1
  Artifact target = 2;  // target image
}

message TransformColorMatch {
  ColorMatchMode color_mode = 1;  // color mode to use
  Artifact image = 2;             // image to match
}

message TransformContrast {
  optional float brightness = 1;  // scale on pixel intensities, 1.0 is no change
  optional float contrast = 2;    // contrast adjustment, 1.0 is no change
}

message TransformDepthCalc {
  optional bool export = 1;        // return the depth map as an artifact
  optional float blend_weight = 2; // blend factor between AdaBins (0.0) and MiDaS (1.0)
}

message TransformMatrix {
  // [a, b, tx]   [x]
  // [c, d, ty] . [y]
  // [0, 0, 1 ]   [1]
  repeated float data = 1 [packed=true]; // 3x3 affine or perspective matrix for 2D
}

message TransformWarp2d {
  BorderMode border_mode = 1; // extrapolation of border pixels
  float translate_x = 4;  // horizontal translation in pixels
  float translate_y = 5;  // vertical translation in pixels
  float rotate = 2;       // rotation in degrees
  float scale = 3;        // scale factor (>1 zooms in, <1 zooms out)  
  optional TransformMatrix matrix = 6;  // 3x3 matrix
}

message TransformWarp3d {
  BorderMode border_mode = 1; // extrapolation of border pixels
  float translate_x = 3;      // horizontal translation
  float translate_y = 4;      // vertical translation
  float translate_z = 5;      // forward translation
  float rotate_x = 6;         // rotation around X-axis in degrees (pitch)
  float rotate_y = 7;         // rotation around Y-axis in degrees (yaw)
  float rotate_z = 8;         // rotation around Z-axis in degrees (roll)
  float near_plane = 9;       // near clipping plane of view frustum
  float far_plane = 10;       // far clipping plane of view frustum
  float fov = 11;             // field of view in degrees
}

message TransformWarpFlow {
  optional Artifact flow_map = 1;   // precomputed flow asset
  optional Artifact prev_frame = 2; // pair of frames to compute flow from
  optional Artifact next_frame = 3;
}

message TransformOperation {
  oneof xform {
    TransformAddNoise add_noise = 1;
    TransformBlend blend = 6;
    TransformColorMatch color_match = 2;
    TransformContrast contrast = 8;
    TransformDepthCalc depth_calc = 7;
    TransformWarp2d warp2d = 3;
    TransformWarp3d warp3d = 4;
    TransformWarpFlow warp_flow = 5;
  }
}

message TransformSequence {
  repeated TransformOperation operations = 1;
}

//
// Asset parameters
//

enum AssetAction {
  ASSET_PUT = 0;
  ASSET_GET = 1;
  ASSET_DELETE = 2;
}

// AssetUse defines how the asset is used within a project.  This enum matches
// the values the project proto.
enum AssetUse {
  ASSET_USE_UNDEFINED = 0;    // Asset does not have use defined
  ASSET_USE_INPUT = 1;        // Asset is used as an input for the project
  ASSET_USE_OUTPUT = 2;       // Asset is an output from the project 
  ASSET_USE_INTERMEDIATE = 3; // Asset is an output from an intermediate step of the project
  ASSET_USE_PROJECT = 4;      // Asset is used as the project file for the project
}

message AssetParameters {
  AssetAction action = 1;
  string project_id = 2;
  AssetUse use = 3;
}

// AnswerMeta is a set of metadata about an answer, usually the operating
// environment.
message AnswerMeta {
  optional string gpu_id = 1;
  optional string cpu_id = 2;
  optional string node_id = 3;
  optional string engine_id = 4;
}

// An Answer is a response to a Request. It is a set of Artifacts, which can be
// of any type and forwarded to the client or the next stage.
message Answer {
  string answer_id = 1;
  string request_id = 2;
  uint64 received = 3;
  uint64 created = 4;
  optional AnswerMeta meta = 6;
  repeated Artifact artifacts = 7;
}

// A Request is a set of Artifacts, which can be of any type with model or
// transform parameters. It is sent to the server, which will respond with an
// Answer.
message Request {
  string engine_id = 1;
  string request_id = 2;
  ArtifactType requested_type = 3;
  repeated Prompt prompt = 4;
  oneof params {
    ImageParameters image = 5;
    ClassifierParameters classifier = 7;
    AssetParameters asset = 8;
    InterpolateParameters interpolate = 11;
  }
  optional ConditionerParameters conditioner = 6;
  optional WeightMethod weight_method = 9;
  repeated Prompt uc_prompt = 10;
}

//
// Stages
//
// A Stage is a single step in a pipeline. Stages are a set of Requests, which are
// sent to the server, and a set of Answers, which are received from the server.

enum StageAction {
  STAGE_ACTION_PASS = 0;
  STAGE_ACTION_DISCARD = 1;
  STAGE_ACTION_RETURN = 2;
}

message OnStatus {
  repeated FinishReason reason = 1;
  optional string target = 2;
  repeated StageAction action = 3;
}

message Stage {
  string id = 1;
  Request request = 2;
  repeated OnStatus on_status = 3;
}

message ChainRequest {
  string request_id = 1;
  repeated Stage stage = 2;
}

//
// gRPC services
//
service GenerationService {
  rpc Generate (Request) returns (stream Answer) {};
  rpc ChainGenerate (ChainRequest) returns (stream Answer) {};
}
